# Chapter 3 - ETL Pipeline Walkthrough


This chapter walks you through building a four-stage ETL pipeline using Azure tools, from ingesting NYC Taxi data to modeling and optional visualization. You’ll gain hands-on experience with Data Factory, Databricks, Synapse, and Power BI.


## Learning Objectives

- Set up cloud-based storage and create a data ingestion pipeline using Azure Data Factory and Blob Storage.
- Process and clean raw data using PySpark in Azure Databricks, and store transformed data in Synapse Analytics. 
- Build data models and create aggregated views for business insights, optionally visualized in Power BI.

By the end of this chapter, you’ll have built a functional, end-to-end ETL pipeline capable of handling structured data for analytics, gaining practical experience in the tools and processes essential to modern data engineering.